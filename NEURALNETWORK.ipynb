{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4bdbd1-11bf-41c8-9ee7-dc4558114b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 100, Epochs: 100\n",
      "→ Test Accuracy: 0.8300\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 100, Epochs: 50\n",
      "→ Test Accuracy: 0.8350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 100, Epochs: 10\n",
      "→ Test Accuracy: 0.8450\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 10, Epochs: 100\n",
      "→ Test Accuracy: 0.8300\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 10, Epochs: 50\n",
      "→ Test Accuracy: 0.8400\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 10, Epochs: 10\n",
      "→ Test Accuracy: 0.8200\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 1, Epochs: 100\n",
      "→ Test Accuracy: 0.8550\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 1, Epochs: 50\n",
      "→ Test Accuracy: 0.8050\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.001, Batch Size: 1, Epochs: 10\n",
      "→ Test Accuracy: 0.8150\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 100, Epochs: 100\n",
      "→ Test Accuracy: 0.8000\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 100, Epochs: 50\n",
      "→ Test Accuracy: 0.8100\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 100, Epochs: 10\n",
      "→ Test Accuracy: 0.8350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 10, Epochs: 100\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 10, Epochs: 50\n",
      "→ Test Accuracy: 0.5350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 10, Epochs: 10\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 1, Epochs: 100\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 1, Epochs: 50\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 0.1, Batch Size: 1, Epochs: 10\n",
      "→ Test Accuracy: 0.5350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 100, Epochs: 100\n",
      "→ Test Accuracy: 0.5700\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 100, Epochs: 50\n",
      "→ Test Accuracy: 0.5800\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 100, Epochs: 10\n",
      "→ Test Accuracy: 0.5950\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 10, Epochs: 100\n",
      "→ Test Accuracy: 0.5400\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 10, Epochs: 50\n",
      "→ Test Accuracy: 0.5900\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 10, Epochs: 10\n",
      "→ Test Accuracy: 0.4600\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 1, Epochs: 100\n",
      "→ Test Accuracy: 0.5400\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 1, Epochs: 50\n",
      "→ Test Accuracy: 0.5350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 256, Learning Rate: 1.0, Batch Size: 1, Epochs: 10\n",
      "→ Test Accuracy: 0.5350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 100, Epochs: 100\n",
      "→ Test Accuracy: 0.8300\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 100, Epochs: 50\n",
      "→ Test Accuracy: 0.8350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 100, Epochs: 10\n",
      "→ Test Accuracy: 0.8550\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 10, Epochs: 100\n",
      "→ Test Accuracy: 0.8250\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 10, Epochs: 50\n",
      "→ Test Accuracy: 0.8150\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 10, Epochs: 10\n",
      "→ Test Accuracy: 0.8550\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 1, Epochs: 100\n",
      "→ Test Accuracy: 0.8250\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 1, Epochs: 50\n",
      "→ Test Accuracy: 0.8400\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.001, Batch Size: 1, Epochs: 10\n",
      "→ Test Accuracy: 0.8200\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 100, Epochs: 100\n",
      "→ Test Accuracy: 0.8200\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 100, Epochs: 50\n",
      "→ Test Accuracy: 0.8150\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 100, Epochs: 10\n",
      "→ Test Accuracy: 0.8400\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 10, Epochs: 100\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 10, Epochs: 50\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 10, Epochs: 10\n",
      "→ Test Accuracy: 0.5350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 1, Epochs: 100\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 1, Epochs: 50\n",
      "→ Test Accuracy: 0.5350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 0.1, Batch Size: 1, Epochs: 10\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 100, Epochs: 100\n",
      "→ Test Accuracy: 0.5200\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 100, Epochs: 50\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 100, Epochs: 10\n",
      "→ Test Accuracy: 0.7150\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 10, Epochs: 100\n",
      "→ Test Accuracy: 0.5300\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 10, Epochs: 50\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 10, Epochs: 10\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 1, Epochs: 100\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 1, Epochs: 50\n",
      "→ Test Accuracy: 0.4650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 128, Learning Rate: 1.0, Batch Size: 1, Epochs: 10\n",
      "→ Test Accuracy: 0.5350\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 100, Epochs: 100\n",
      "→ Test Accuracy: 0.8300\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 100, Epochs: 50\n",
      "→ Test Accuracy: 0.8450\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 100, Epochs: 10\n",
      "→ Test Accuracy: 0.8400\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 10, Epochs: 100\n",
      "→ Test Accuracy: 0.8100\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 10, Epochs: 50\n",
      "→ Test Accuracy: 0.8200\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 10, Epochs: 10\n",
      "→ Test Accuracy: 0.8650\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 1, Epochs: 100\n",
      "→ Test Accuracy: 0.8300\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 1, Epochs: 50\n",
      "→ Test Accuracy: 0.8300\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.001, Batch Size: 1, Epochs: 10\n",
      "→ Test Accuracy: 0.8200\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.1, Batch Size: 100, Epochs: 100\n",
      "→ Test Accuracy: 0.8200\n",
      "\n",
      "Training with Activation: relu, Hidden Layer: 64, Learning Rate: 0.1, Batch Size: 100, Epochs: 50\n"
     ]
    }
   ],
   "source": [
    "#Q4:WAP to evaluate the performance of implemented three-layer neural network with variations in\n",
    "#activation functions, size of hidden layer, learning rate, batch size and number of epochs.\n",
    "\n",
    "#Model Description:- \n",
    "#Model Overview\n",
    "#This model is a binary classification neural network designed to evaluate different hyperparameter configurations. It is implemented using TensorFlow and Keras and is trained on a synthetic dataset generated using sklearn.datasets.make_classification(). The dataset contains 1000 samples with 20 features, and the target variable is binary (0 or 1).\n",
    "\n",
    "#The model follows a feedforward architecture with three layers:\n",
    "\n",
    "#Input Layer: Fully connected (Dense) layer with a variable number of neurons (hidden_layer_size) and an activation function (relu, tanh, or sigmoid).\n",
    "#Hidden Layer: A second Dense layer with hidden_layer_size // 2 neurons (minimum of 1 neuron to prevent invalid configurations) and the same activation function.\n",
    "#Output Layer: A single neuron with a sigmoid activation function for binary classification.\n",
    "\n",
    "#Training Process\n",
    "#The dataset is standardized using StandardScaler to improve training stability.\n",
    "#The model is compiled using the Adam optimizer, with varying learning rates (0.1, 0.001, and 1.0).\n",
    "#Binary cross-entropy loss is used, as this is a classification problem.\n",
    "#The model is trained with different batch sizes (100, 10, 1) and epochs (100, 50, 10) to evaluate performance under different settings.\n",
    "#Test accuracy is reported for each configuration.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Function to create and evaluate the model\n",
    "def evaluate_nn(activation, hidden_layer_size, learning_rate, batch_size, epochs):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_layer_size, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        Dense(max(1, hidden_layer_size // 2), activation=activation),  # Ensure valid layer size\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    print(f\"Training with Activation: {activation}, Hidden Layer: {hidden_layer_size}, Learning Rate: {learning_rate}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=0)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"→ Test Accuracy: {test_acc:.4f}\\n\")\n",
    "    \n",
    "# Variations to test\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "hidden_layer_sizes = [256, 128, 64]\n",
    "learning_rates = [0.001, 0.1, 1.0]\n",
    "batch_sizes = [100, 10, 1]  # Batch size of 1 is slow but kept for experimentation\n",
    "epochs_list = [100, 50, 10]\n",
    "\n",
    "# Running experiments\n",
    "for activation in activations:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        for learning_rate in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                for epochs in epochs_list:\n",
    "                    evaluate_nn(activation, hidden_layer_size, learning_rate, batch_size, epochs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Comments:-\n",
    "This model is a simple neural network for binary classification, testing different hyperparameters to find the best combination. \n",
    "Future improvements could include deeper architectures, better tuning, and real-world dataset applications. 🚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59105093-d885-4284-a938-850d628fac7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
